# Test info

- Name: Teacher Interface - Comprehensive Test Suite >> Error Handling >> should show error if trying to record when speech recognition is unavailable
- Location: /Users/yamijala/gitprojects/AIVoiceTranslator/tests/e2e/teacher.spec.ts:391:3

# Error details

```
Error: Timed out 3000ms waiting for expect(locator).toContainText(expected)

Locator: locator('#status')
Expected string: "Speech recognition not available"
Received string: "Microphone access denied or unavailable"
Call log:
  - expect.toContainText with timeout 3000ms
  - waiting for locator('#status')
    5 × locator resolved to <div id="status" class="status">Registered as teacher</div>
      - unexpected value "Registered as teacher"
    2 × locator resolved to <div id="status" class="status">Microphone access denied or unavailable</div>
      - unexpected value "Microphone access denied or unavailable"

    at /Users/yamijala/gitprojects/AIVoiceTranslator/tests/e2e/teacher.spec.ts:420:46
```

# Test source

```ts
  320 |       
  321 |       // Find transcription messages
  322 |       const transcriptionMessages = messages.filter((msg: any) => msg.type === 'transcription');
  323 |       
  324 |       // Verify transcription message was sent
  325 |       expect(transcriptionMessages.length).toBeGreaterThan(0);
  326 |       
  327 |       const transcriptionMessage = transcriptionMessages[0];
  328 |       expect(transcriptionMessage).toMatchObject({
  329 |         type: 'transcription',
  330 |         text: 'Hello, this is a test transcription',
  331 |         timestamp: expect.any(Number),
  332 |         isFinal: true
  333 |       });
  334 |     });
  335 |
  336 |     test('should send audio data through WebSocket', async () => {
  337 |       // Wait for WebSocket connection
  338 |       await expect(page.locator('#status')).toContainText('Registered as teacher', { timeout: 10000 });
  339 |       
  340 |       // Intercept WebSocket messages
  341 |       const wsMessages: any[] = [];
  342 |       await page.addInitScript(() => {
  343 |         const originalSend = WebSocket.prototype.send;
  344 |         WebSocket.prototype.send = function(data: any) {
  345 |           try {
  346 |             const parsed = JSON.parse(data);
  347 |             (window as any).__wsMessages = (window as any).__wsMessages || [];
  348 |             (window as any).__wsMessages.push(parsed);
  349 |           } catch (e) {
  350 |             // Not JSON, ignore
  351 |           }
  352 |           return originalSend.call(this, data);
  353 |         };
  354 |       });
  355 |       
  356 |       // Reload to apply WebSocket interception
  357 |       await page.reload();
  358 |       await page.waitForLoadState('domcontentloaded');
  359 |       await expect(page.locator('#status')).toContainText('Registered as teacher', { timeout: 10000 });
  360 |       
  361 |       // Start recording
  362 |       const recordButton = page.locator('#recordButton');
  363 |       await recordButton.click();
  364 |       
  365 |       // Wait for audio to be sent (MediaRecorder sends data after 150ms in our mock)
  366 |       await page.waitForTimeout(300);
  367 |       
  368 |       // Get WebSocket messages
  369 |       const messages = await page.evaluate(() => (window as any).__wsMessages || []);
  370 |       
  371 |       // Find audio messages
  372 |       const audioMessages = messages.filter((msg: any) => msg.type === 'audio');
  373 |       
  374 |       // Verify audio message was sent
  375 |       expect(audioMessages.length).toBeGreaterThan(0);
  376 |       
  377 |       const audioMessage = audioMessages[0];
  378 |       expect(audioMessage).toMatchObject({
  379 |         type: 'audio',
  380 |         sessionId: expect.any(String),
  381 |         data: expect.any(String), // base64 encoded
  382 |         isFirstChunk: true,
  383 |         isFinalChunk: false,
  384 |         language: expect.any(String)
  385 |       });
  386 |     });
  387 |   });
  388 |
  389 |   // Error Handling Tests
  390 |   test.describe('Error Handling', () => {
  391 |   test('should show error if trying to record when speech recognition is unavailable', async ({ browser, browserName }) => {
  392 |     const contextOptions: any = {};
  393 |     if (browserName === 'chromium') {
  394 |       contextOptions.permissions = ['microphone'];
  395 |     }
  396 |     const context = await browser.newContext(contextOptions);
  397 |     const newPage = await context.newPage(); 
  398 |     
  399 |     await newPage.addInitScript(() => {
  400 |       // Explicitly disable SpeechRecognition APIs for this specific test page.
  401 |       // This will override any mock SpeechRecognition that might be set up by a global beforeEach for this newPage.
  402 |       (window as any).SpeechRecognition = undefined;
  403 |       (window as any).webkitSpeechRecognition = undefined;
  404 |
  405 |       // Note: We are intentionally NOT re-mocking getUserMedia, MediaRecorder, etc., here.
  406 |       // This newPage context will inherit the general mocks from the global beforeEach if they apply,
  407 |       // or use browser defaults if not overridden. The critical part for this test is that
  408 |       // SpeechRecognition itself is unavailable.
  409 |     });
  410 |     
  411 |     await newPage.goto('http://127.0.0.1:5000/teacher'); 
  412 |     await newPage.waitForLoadState('domcontentloaded');
  413 |
  414 |     // Wait for the record button to be visible and then click it
  415 |     const recordButton = newPage.locator('#recordButton');
  416 |     await expect(recordButton).toBeVisible({ timeout: 5000 });
  417 |     await recordButton.click();
  418 |     
  419 |     // Assert that the status message indicates speech recognition is not available
> 420 |     await expect(newPage.locator('#status')).toContainText('Speech recognition not available', { timeout: 3000 });
      |                                              ^ Error: Timed out 3000ms waiting for expect(locator).toContainText(expected)
  421 |     
  422 |     // Record button should remain enabled as recording couldn't start
  423 |     await expect(recordButton).toBeEnabled();
  424 |     
  425 |     // Clean up: close the page and context
  426 |     await newPage.close();
  427 |     await context.close();
  428 |     });
  429 |
  430 |     test('should handle recording errors gracefully', async () => {
  431 |       // Create a new page with error-triggering speech recognition
  432 |       const context = await page.context();
  433 |       const errorPage = await context.newPage();
  434 |       
  435 |       // Set up error mock before page loads
  436 |       await errorPage.addInitScript(() => {
  437 |         // Mock MediaRecorder (same as before)
  438 |         const mockStream = {
  439 |           getTracks: () => [{
  440 |             kind: 'audio',
  441 |             stop: () => {},
  442 |             enabled: true
  443 |           }],
  444 |           getAudioTracks: () => [{
  445 |             kind: 'audio',
  446 |             stop: () => {},
  447 |             enabled: true
  448 |           }],
  449 |           active: true
  450 |         };
  451 |         
  452 |         (window as any).MediaRecorder = class MockMediaRecorder {
  453 |           state = 'inactive';
  454 |           ondataavailable: ((event: any) => void) | null = null;
  455 |           onstop: (() => void) | null = null;
  456 |           
  457 |           constructor(stream: any, options: any) {
  458 |             console.log('MockMediaRecorder created');
  459 |           }
  460 |           
  461 |           start(timeslice?: number) {
  462 |             this.state = 'recording';
  463 |           }
  464 |           
  465 |           stop() {
  466 |             this.state = 'inactive';
  467 |             if (this.onstop) {
  468 |               this.onstop();
  469 |             }
  470 |           }
  471 |           
  472 |           static isTypeSupported(mimeType: string) {
  473 |             return true;
  474 |           }
  475 |         };
  476 |         
  477 |         Object.defineProperty(navigator, 'mediaDevices', {
  478 |           writable: true,
  479 |           value: {
  480 |             getUserMedia: async (constraints: any) => {
  481 |               return mockStream as any;
  482 |             }
  483 |           }
  484 |         });
  485 |         
  486 |         // Mock Speech Recognition that triggers error
  487 |         (window as any).webkitSpeechRecognition = class MockSpeechRecognition {
  488 |           continuous = false;
  489 |           interimResults = false;
  490 |           lang = 'en-US';
  491 |           onresult: ((event: any) => void) | null = null;
  492 |           onerror: ((event: any) => void) | null = null;
  493 |           onend: (() => void) | null = null;
  494 |           
  495 |           start() {
  496 |             console.log('Speech recognition started (error mock)');
  497 |             // Trigger error after a short delay
  498 |             setTimeout(() => {
  499 |               if (this.onerror) {
  500 |                 this.onerror({ error: 'network' });
  501 |               }
  502 |             }, 100);
  503 |           }
  504 |           
  505 |           stop() {
  506 |             if (this.onend) {
  507 |               this.onend();
  508 |             }
  509 |           }
  510 |         };
  511 |       });
  512 |       
  513 |       // Navigate to teacher page
  514 |       await errorPage.goto('http://127.0.0.1:5000/teacher');
  515 |       await errorPage.waitForLoadState('domcontentloaded');
  516 |       
  517 |       // Wait for WebSocket connection
  518 |       await expect(errorPage.locator('#status')).toContainText('Registered as teacher', { timeout: 10000 });
  519 |       
  520 |       // Try to start recording
```